{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:01.710188Z","iopub.status.busy":"2022-11-08T00:20:01.709744Z","iopub.status.idle":"2022-11-08T00:20:01.740565Z","shell.execute_reply":"2022-11-08T00:20:01.739697Z","shell.execute_reply.started":"2022-11-08T00:20:01.710100Z"},"trusted":true},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:16.064685Z","iopub.status.busy":"2022-11-08T00:20:16.064020Z","iopub.status.idle":"2022-11-08T00:20:21.359873Z","shell.execute_reply":"2022-11-08T00:20:21.358906Z","shell.execute_reply.started":"2022-11-08T00:20:16.064652Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","import tensorflow_addons as tfa\n","\n","from tensorflow.keras import Model\n","\n","from IPython.display import clear_output\n","from tensorflow.keras.layers import Dense, Conv2D, Input, Reshape, LeakyReLU, UpSampling2D, Flatten, AveragePooling2D\n","import tensorflow.keras.initializers as initer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:21.362109Z","iopub.status.busy":"2022-11-08T00:20:21.361497Z","iopub.status.idle":"2022-11-08T00:20:21.371203Z","shell.execute_reply":"2022-11-08T00:20:21.366227Z","shell.execute_reply.started":"2022-11-08T00:20:21.362079Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 32\n","LAMBDA = 10\n","EPOCHs = 200\n","NOISE_DIM = 128\n","\n","CURRENT_EPOCH = 1\n","SAVE_EVERY_N_EPOCH = 5\n","N_CRITIC = 5\n","\n","LOG_DIR = './results/logs/'\n","CKPT_DIR = './results/models_weight'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:23.997191Z","iopub.status.busy":"2022-11-08T00:20:23.996718Z","iopub.status.idle":"2022-11-08T00:20:28.170834Z","shell.execute_reply":"2022-11-08T00:20:28.169888Z","shell.execute_reply.started":"2022-11-08T00:20:23.997150Z"},"trusted":true},"outputs":[],"source":["# preprocess data\n","import os \n","import pathlib\n","\n","def normalize(image):\n","    '''\n","        normalizing the images to [-1, 1]\n","    '''\n","    image = tf.cast(image, tf.float32)\n","    image = (image - 127.5) / 127.5\n","    return image\n","\n","def preprocess_image(file_path, img_size=64):\n","\n","    images = tf.io.read_file(file_path)\n","\n","    images = tf.image.decode_jpeg(images, channels=3) \n","    images = tf.image.resize(images, (img_size, img_size))\n","    images = normalize(images)\n","\n","    return images\n","\n","data_path = pathlib.Path(\"/Users/lubaixun/tensorflow-DL/data/faces\")\n","\n","file_path = [str(path) for path in data_path.glob('*.jpg')]\n","\n","print(len(file_path))\n","train_data_path = tf.data.Dataset.from_tensor_slices(file_path)\n","train_data = train_data_path.map(preprocess_image).shuffle(100).batch(BATCH_SIZE)\n","\n","imgs = next(iter(train_data))[0]\n","clear_output()\n","\n","plt.imshow(imgs)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:30.045193Z","iopub.status.busy":"2022-11-08T00:20:30.043915Z","iopub.status.idle":"2022-11-08T00:20:30.057274Z","shell.execute_reply":"2022-11-08T00:20:30.056010Z","shell.execute_reply.started":"2022-11-08T00:20:30.045131Z"},"trusted":true},"outputs":[],"source":["class AdaNorm(tf.keras.layers.Layer):\n","    def __init__(self, epsilon=1e-6):\n","        super().__init__()\n","        self.epsilon = epsilon\n","    \n","    def call(self, x):\n","        \n","        mean = tf.math.reduce_mean(x, axis=(1, 2), keepdims=True)\n","        variance = tf.reduce_mean(tf.math.square(x), axis=(1, 2), keepdims=True)\n","        \n","        x -= mean\n","        x *= tf.math.rsqrt(variance + self.epsilon)\n","        return x\n","\n","class AdaIN(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","        \n","    def call(self, inp):\n","        x, w = inp\n","        y = tf.reshape(self.dense(w), [-1, 2, 1, 1, self.c])\n","        out = y[:, 0] * x + y[:, 1]\n","        return out\n","    \n","    def build(self, input_shapes):\n","        x_shape, w_shape = input_shapes\n","        self.c = x_shape[-1]\n","        self.dense = Dense(self.c*2)\n","\n","        \n","class AddNoise(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","        \n","    def call(self, inp):\n","        x, noise = inp\n","        noise = noise[:, :x.shape[1], :x.shape[2], :]\n","        return self.b * noise + x\n","    \n","    def build(self, input_shape):\n","        n, h, w, c = input_shape[0]\n","        initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n","        self.b = self.add_weight(\n","            shape=[1, 1, 1, c], initializer=initializer, trainable=True, name=\"noise_weights\"\n","        )\n","    \n","        \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:33.690385Z","iopub.status.busy":"2022-11-08T00:20:33.690024Z","iopub.status.idle":"2022-11-08T00:20:33.698663Z","shell.execute_reply":"2022-11-08T00:20:33.697288Z","shell.execute_reply.started":"2022-11-08T00:20:33.690356Z"},"trusted":true},"outputs":[],"source":["def LatentMapping(x, latent_dim, num_layers=5):\n","    x = Dense(latent_dim, kernel_initializer=initer.HeNormal())(x)\n","\n","    for _ in range(num_layers):\n","        x = LeakyReLU(0.2)(x)\n","        x = Dense(latent_dim, kernel_initializer=initer.HeNormal())(x)\n","\n","    return x\n","\n","def StyleBlock(inp, filter, up_sample=True):\n","    x, w, noise = inp\n","    \n","    x = AdaIN()((x, w))\n","    if up_sample:\n","        x = UpSampling2D((2, 2), interpolation=\"bilinear\")(x)\n","\n","    x = Conv2D(filter, 3, 1, padding=\"same\", kernel_initializer=initer.HeNormal())(x)\n","    x = LeakyReLU(0.2)(x)\n","    x = AddNoise()((x, noise))\n","    x = AdaNorm()(x)\n","\n","    return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:35.747549Z","iopub.status.busy":"2022-11-08T00:20:35.746938Z","iopub.status.idle":"2022-11-08T00:20:35.759608Z","shell.execute_reply":"2022-11-08T00:20:35.758699Z","shell.execute_reply.started":"2022-11-08T00:20:35.747515Z"},"trusted":true},"outputs":[],"source":["def get_generator(img_shape, latent_dim=NOISE_DIM):\n","    n_style_block = 0\n","    inp_size = res = 4\n","    while res <= img_shape[1]:\n","        n_style_block += 1\n","        res *= 2\n","    \n","    inp = Input((1,), name=\"input_tensor\")\n","    z = Input((n_style_block, latent_dim,), name=\"z\")\n","    noise = Input((img_shape[0], img_shape[1], 1), name=\"noise\")\n","\n","    w = LatentMapping(z, latent_dim)\n","\n","    input_tensor = Dense(inp_size * inp_size * 256, kernel_initializer=initer.HeNormal())(inp)\n","    input_tensor = Reshape((inp_size, inp_size, -1))(input_tensor)\n","\n","\n","    x = AddNoise()((input_tensor, noise))\n","    x = AdaNorm()(x)\n","    for i in range(n_style_block):\n","        x = StyleBlock((x, w[:, i], noise), 256, up_sample=False if i == 0 else True)\n","\n","    out = Conv2D(3, 7, 1, padding=\"same\", activation='tanh')(x)\n","\n","    model = Model([inp, z, noise], out, name=\"generator\")\n","\n","    return model, n_style_block\n","\n","\n","#model, n = get_generator((64, 64, 3))\n","#model.summary()\n","\n","'''\n","tf.keras.utils.plot_model(\n","    model,\n","    to_file='model.png',\n","    show_shapes=True)\n","'''\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:39.148657Z","iopub.status.busy":"2022-11-08T00:20:39.148310Z","iopub.status.idle":"2022-11-08T00:20:39.159097Z","shell.execute_reply":"2022-11-08T00:20:39.158042Z","shell.execute_reply.started":"2022-11-08T00:20:39.148627Z"},"trusted":true},"outputs":[],"source":["def get_discriminator(img_dim, filter):\n","\n","    inp = Input(img_dim)\n","\n","    x = Conv2D(filter, 3, 1, padding='same')(inp)\n","    x = LeakyReLU(0.2)(x)\n","\n","    x = Conv2D(filter*2, 3, 1, padding='same')(x)\n","    x = tfa.layers.InstanceNormalization()(x)\n","    x = LeakyReLU(0.2)(x)\n","    x = AveragePooling2D()(x)\n","    \n","\n","    x = Conv2D(filter*4, 3, 1, padding='same')(x)\n","    x = tfa.layers.InstanceNormalization()(x)\n","    x = LeakyReLU(0.2)(x)\n","    x = AveragePooling2D()(x)\n","\n","    x = Conv2D(filter*8, 3, 1, padding='same')(x)\n","    x = tfa.layers.InstanceNormalization()(x)\n","    x = LeakyReLU(0.2)(x)\n","    x = AveragePooling2D()(x)\n","\n","    x = Conv2D(filter*16, 3, 1, padding='same')(x)\n","    x = tfa.layers.InstanceNormalization()(x)\n","    x = LeakyReLU(0.2)(x)\n","    x = AveragePooling2D()(x)\n","\n","    x = Flatten()(x)\n","    x = Dense(128)(x)\n","    x = LeakyReLU(0.2)(x)\n","    out = Dense(1)(x)\n","\n","    model = Model(inp, out)\n","    return model\n","\n","#model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:40.999364Z","iopub.status.busy":"2022-11-08T00:20:40.998958Z","iopub.status.idle":"2022-11-08T00:20:42.101443Z","shell.execute_reply":"2022-11-08T00:20:42.100503Z","shell.execute_reply.started":"2022-11-08T00:20:40.999333Z"},"trusted":true},"outputs":[],"source":["generator, n_block = get_generator((64, 64, 3))\n","discriminator = get_discriminator((64, 64, 3), 32)\n","\n","G_optimizer = tf.keras.optimizers.Adam(0.0001,beta_1=0.5)\n","D_optimizer = tf.keras.optimizers.Adam(0.0001,beta_1=0.5)\n","\n","ckpt = tf.train.Checkpoint(models=[generator, discriminator])\n","                           \n","# save model\n","\n","summary_Writer = tf.summary.create_file_writer(LOG_DIR)\n","ckpt_manager = tf.train.CheckpointManager(ckpt, CKPT_DIR, max_to_keep=5)\n","\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    latest_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n","    CURRENT_EPOCH = latest_epoch * SAVE_EVERY_N_EPOCH + 1\n","    print ('Latest checkpoint of epoch {} restored!!'.format(CURRENT_EPOCH))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:45.639698Z","iopub.status.busy":"2022-11-08T00:20:45.639347Z","iopub.status.idle":"2022-11-08T00:20:45.653298Z","shell.execute_reply":"2022-11-08T00:20:45.652275Z","shell.execute_reply.started":"2022-11-08T00:20:45.639668Z"},"trusted":true},"outputs":[],"source":["# define train step\n","\n","def WGAN_GP_train_d_step(real_image, batch_size, n_style_block=n_block):\n","\n","    epsilon = tf.random.uniform(shape=[batch_size, 1, 1, 1], minval=0, maxval=1)\n","\n","    inp = tf.ones((batch_size, 1))\n","    z = tf.repeat(tf.random.normal((batch_size, 1, NOISE_DIM)), n_style_block, axis=1)\n","    noise = tf.random.normal((batch_size, real_image.shape[1], real_image.shape[2], 1))\n","    \n","    with tf.GradientTape(persistent=True) as d_tape:\n","        with tf.GradientTape() as gp_tape:\n","\n","            fake_image = generator([inp, z, noise], training=True)\n","            fake_image_mixed = epsilon * tf.dtypes.cast(real_image, tf.float32) + ((1 - epsilon) * fake_image)\n","            fake_mixed_pred = discriminator([fake_image_mixed], training=True)\n","        \n","        grads = gp_tape.gradient(fake_mixed_pred, fake_image_mixed)\n","        grad_norms = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n","        gradient_penalty = tf.reduce_mean(tf.square(grad_norms - 1))\n","        \n","        fake_pred = discriminator([fake_image], training=True)\n","        real_pred = discriminator([real_image], training=True)\n","        \n","        D_loss = tf.reduce_mean(fake_pred) - tf.reduce_mean(real_pred) + LAMBDA * gradient_penalty\n","    \n","    D_gradients = d_tape.gradient(D_loss, discriminator.trainable_variables)                                 \n","    D_optimizer.apply_gradients(zip(D_gradients, discriminator.trainable_variables))\n","    \n","    return D_loss\n","                                                \n","\n","def WGAN_GP_train_g_step(real_image, batch_size, n_style_block=n_block):\n","\n","    inp = tf.ones((batch_size, 1))\n","    z = tf.repeat(tf.random.normal((batch_size, 1, NOISE_DIM)), n_style_block, axis=1)\n","    noise = tf.random.normal((batch_size, real_image.shape[1], real_image.shape[2], 1))\n","\n","    with tf.GradientTape() as g_tape:\n","        fake_image = generator([inp, z, noise], training=True)\n","        fake_pred = discriminator([fake_image], training=True)\n","        G_loss = -tf.reduce_mean(fake_pred)\n","        \n","    G_gradients = g_tape.gradient(G_loss, generator.trainable_variables)                                \n","    G_optimizer.apply_gradients(zip(G_gradients,generator.trainable_variables))\n","    \n","    return G_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:48.144715Z","iopub.status.busy":"2022-11-08T00:20:48.143823Z","iopub.status.idle":"2022-11-08T00:20:48.153747Z","shell.execute_reply":"2022-11-08T00:20:48.152366Z","shell.execute_reply.started":"2022-11-08T00:20:48.144667Z"},"trusted":true},"outputs":[],"source":["OUTPUT_PATH = r'./results/out_imgs/'\n","if not os.path.exists(OUTPUT_PATH):\n","    os.mkdir(OUTPUT_PATH)\n","    \n","def generate_and_save_images(model, epoch, path=OUTPUT_PATH, num_sample=16, figure_size=(12, 12), subplot=(4,4), save=True):\n","    inp = tf.ones((num_sample, 1))\n","    z = tf.repeat(tf.random.normal((num_sample, 1, NOISE_DIM)), n_block, axis=1)\n","    noise = tf.random.normal((num_sample, 64, 64, 1))\n","\n","    predictions = model.predict([inp, z, noise])\n","    \n","    for i in range(predictions.shape[0]):\n","        axs = plt.subplot(subplot[0], subplot[1], i+1)\n","        axs.imshow(predictions[i] * 0.5 + 0.5)\n","        plt.axis('off')\n","    if save:\n","        plt.savefig(os.path.join(path, 'image_at_epoch_{:04d}.png'.format(epoch)))   \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-08T00:20:51.749963Z","iopub.status.busy":"2022-11-08T00:20:51.749595Z"},"trusted":true},"outputs":[],"source":["import time \n","n_critic_count = 0\n","\n","for epoch in range(CURRENT_EPOCH, EPOCHs+1):\n","    start = time.time()\n","    \n","    print('Start of epoch %d' % (epoch,))\n","    \n","    for step, imgs in enumerate(train_data):\n","        current_batch_size = imgs.shape[0]\n","        clear_output()\n","        # Train critic (discriminator)\n","        \n","        d_loss = WGAN_GP_train_d_step(imgs, batch_size=current_batch_size)\n","        n_critic_count += 1\n","        \n","        if n_critic_count >= N_CRITIC: \n","            \n","            # Train generator\n","            g_loss = WGAN_GP_train_g_step(imgs, batch_size=current_batch_size)\n","            n_critic_count = 0\n","        \n","        if step % 100 == 0:\n","            print ('.', end='')\n","        \n","\n","    print('\\n Epoch %d finished ~ ~ ~ '  % (epoch,))\n","    \n","    \n","    with summary_Writer.as_default():\n","        tf.summary.scalar('g_loss', g_loss, step=epoch)\n","        tf.summary.scalar('d_loss', d_loss, step=epoch)\n","        \n","    \n","    if epoch % SAVE_EVERY_N_EPOCH == 0:\n","\n","        clear_output(wait=True)\n","    \n","        #save model\n","        ckpt_save_path = ckpt_manager.save()\n","        print ('Saving checkpoint for epoch {} at {}'.format(epoch, ckpt_save_path))\n","                                                             \n","    print ('Time taken for epoch {} is {} sec\\n'.format(epoch,time.time()-start))                                             \n","    generate_and_save_images(generator, epoch)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%tensorboard --logdir LOG_DIR"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.13","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"96740db8853225a28343985eb2afde8386a2ceb81d2b3b54d41408b8c491d78e"}}},"nbformat":4,"nbformat_minor":4}
