{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os \n","import cv2\n","import random\n","import torch\n","import math\n","import time\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","\n","from tqdm import *\n","from glob import glob\n","from PIL import Image\n","from math import log2\n","\n","from torchvision import transforms\n","from torch import nn, einsum\n","from torch.autograd import grad as torch_grad\n","from torch.nn import Linear, SiLU, Upsample,LeakyReLU, \\\n","                     Conv2d, ReLU, InstanceNorm2d, Tanh, AvgPool2d\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class InpaintData(torch.utils.data.Dataset):\n","    def __init__(self, path, img_size=[64, 64]):\n","        super().__init__()\n","        self.file_list = []\n","        self.img_size = img_size\n","        self.transforms = transforms.Compose([\n","            # can put some augmentation here\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) \n","        ])\n","        for file_name in glob(f'{path}/**/*.jpg', recursive=True):\n","            self.file_list.append(file_name)\n","            \n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        file_name = self.file_list[idx]\n","        img = Image.open(file_name).convert('RGB')\n","        img = transforms.functional.resize(img, self.img_size, Image.BICUBIC)\n","        img = self.transforms(img)\n","        return img "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path = \"/kaggle/input/celebahq/celeba_hq/train\"\n","dataset = InpaintData(path)\n","\n","train_data = torch.utils.data.DataLoader(\n","                    dataset,\n","                    batch_size=16,\n","                    shuffle= True,\n","                    pin_memory=True,\n","                    drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class PixelNorm(nn.Module):\n","    def __init__(self):\n","        super(PixelNorm, self).__init__()\n","        self.epsilon = 1e-8\n","\n","    def forward(self, x):\n","        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n","    \n","class AdaIN(nn.Module):\n","    def __init__(self, channels, w_dim):\n","        super().__init__()\n","        self.instance_norm = InstanceNorm2d(channels)\n","        self.scale = Linear(w_dim, channels)\n","        self.bias = Linear(w_dim, channels)\n","\n","    def forward(self, x, w):\n","        x = self.instance_norm(x)\n","        scale = self.scale(w)[:, :, None, None]\n","        bias = self.bias(w)[:, :, None, None]\n","        return scale * x + bias\n","\n","class AddNoise(nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.zeros(1, channels, 1, 1))\n","\n","    def forward(self, x):\n","        noise = torch.randn((x.shape[0], 1, x.shape[2], x.shape[3]), device=x.device)\n","        return x + self.weight * noise\n","\n","class MappingNetwork(nn.Module):\n","    def __init__(self, z_dim, w_dim, n_layers=8):\n","        super().__init__()\n","        layers = [PixelNorm(), Linear(z_dim, w_dim), ReLU()]\n","\n","        for _ in range(n_layers - 1):\n","            layers.extend([Linear(w_dim, w_dim), ReLU()])\n","        self.mapping = nn.Sequential(*layers)\n","    def forward(self, x):\n","        return self.mapping(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class G_block(nn.Module):\n","    def __init__(self, latent_dim, in_channel, out_channel, upsample=True):\n","        super().__init__()\n","        self.upsample = None\n","        if upsample:\n","            self.upsample = Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n","\n","        self.conv1 = Conv2d(in_channel, out_channel, kernel_size=3, padding=1)\n","        self.conv2 = Conv2d(out_channel, out_channel, kernel_size=3, padding=1)\n","        self.AddNoise1 = AddNoise(out_channel)\n","        self.AddNoise2 = AddNoise(out_channel)\n","        self.AdaIN1 = AdaIN(out_channel, latent_dim)\n","        self.AdaIN2 = AdaIN(out_channel, latent_dim)\n","        self.leaky = LeakyReLU(0.2, inplace=True)\n","\n","    def forward(self, x, w):\n","        if self.upsample is not None:\n","            x = self.upsample(x)\n","        x = self.AdaIN1(self.leaky(self.AddNoise1(self.conv1(x))), w)\n","        x = self.AdaIN2(self.leaky(self.AddNoise2(self.conv2(x))), w)\n","        return x\n","    \n","class D_block(nn.Module):\n","    def __init__(self, in_channel, out_channel, downsample = True):\n","        super().__init__()\n","        self.conv_res = Conv2d(in_channel, out_channel, kernel_size=1, padding=0)\n","        self.downsample = None\n","        if downsample:\n","            self.downsample = AvgPool2d(kernel_size=2, stride=2)\n","            \n","        self.net = nn.Sequential(\n","            Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n","            LeakyReLU(0.2, inplace=True),\n","            Conv2d(out_channel, out_channel, kernel_size=3, padding=1),\n","            LeakyReLU(0.2, inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        res = self.conv_res(x)\n","        x = self.net(x)\n","        x = (x + res) * (1 / math.sqrt(2))\n","        if self.downsample is not None:\n","            x = self.downsample(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, img_size, z_dim , fmap_max=512, fmap_min=64):\n","        super().__init__()\n","        self.z_dim = z_dim\n","        self.num_layers = int(math.log2(img_size)-1)\n","        # Generate filter sizes for each layer\n","        filters = [min(fmap_max, fmap_min * (2 ** i)) for i in range(self.num_layers + 1)]\n","        filters = list(reversed(filters))\n","        \n","        self.mapping = MappingNetwork(z_dim, z_dim)\n","        self.init_input = nn.Parameter(torch.ones(1, filters[0], 4, 4))\n","        self.init_conv = Conv2d(filters[0], filters[0], 3, padding=1)\n","        self.leaky = LeakyReLU(0.2, inplace=True)\n","        self.final_block = nn.Sequential(\n","            Conv2d(filters[-1], 3, 3, padding=1),\n","            Tanh()\n","        )\n","        self.blocks = nn.ModuleList([])\n","        for i, (in_channel, out_channel) in enumerate(zip(filters[:-1], filters[1:])):\n","            # Apply upscaling except for the first block\n","            up_sample = i != 0\n","            g_block = G_block(z_dim, in_channel, out_channel, up_sample)\n","            self.blocks.append(g_block)\n","\n","    def forward(self, latents):\n","        batch_size = latents.shape[0]\n","        styles = self.mapping(F.normalize(latents, dim=1))\n","        styles = styles.view([-1, batch_size, self.z_dim])\n","\n","        x = self.init_conv(self.init_input)\n","        x = self.leaky(x)\n","        for block, style in zip(self.blocks, styles):\n","            x = block(x, style)\n","        return self.final_block(x)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, img_size, fmap_min=32, fmap_max=512):\n","        super().__init__()\n","        self.num_layers = int(log2(img_size) - 1)\n","        # Generate filter sizes for each layer\n","        filters = [3] + [min(fmap_max, fmap_min * (2 ** i)) for i in range(self.num_layers)]\n","\n","        self.blocks = nn.ModuleList([])\n","        for i, (in_channel, out_channel) in enumerate(zip(filters[:-1], filters[1:])):\n","            # Apply downsampling except for the last block\n","            down_sample = i != (len(filters) - 2)\n","            d_block = D_block(in_channel, out_channel, down_sample)\n","            self.blocks.append(d_block)\n","            \n","        self.final_block = nn.Sequential(\n","            # The output shape will become [1, 1, 1]\n","            Conv2d(filters[-1], filters[-1], kernel_size=3, padding=1),\n","            LeakyReLU(0.2),\n","            Conv2d(filters[-1], filters[-1], kernel_size=4, padding=0, stride=1),\n","            LeakyReLU(0.2),\n","            Conv2d(filters[-1], 1, kernel_size=1, padding=0, stride=1)\n","        )\n","\n","    def forward(self, x):\n","        for block in self.blocks:\n","            x = block(x)\n","        x = self.final_block(x).squeeze()\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Helper function\n","def requires_grad(model, flag=True):\n","    for p in model.parameters():\n","        p.requires_grad = flag\n","\n","def d_loss_fn(real_pred, fake_pred):\n","    real_loss = F.softplus(-real_pred)\n","    fake_loss = F.softplus(fake_pred)\n","    return real_loss.mean() + fake_loss.mean()\n","    \n","def g_loss_fn(fake_pred):\n","    loss = F.softplus(-fake_pred).mean()\n","    return loss\n","\n","def gradient_penalty(images, output, weight = 10):\n","    batch_size = images.shape[0]\n","    gradients = torch_grad(outputs=output, inputs=images,\n","                           grad_outputs=torch.ones(output.size(), device=images.device),\n","                           create_graph=True, retain_graph=True, only_inputs=True)[0]\n","\n","    gradients = gradients.reshape(batch_size, -1)\n","    return weight * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","\n","def get_g_input(batch, img_size, n_layers, latent_dim, device):\n","    styles = torch.randn(batch, 1, latent_dim).cuda(device)\n","    styles = torch.tile(styles, [1, n_layers, 1])\n","    return styles"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Trainer():\n","    def __init__(self, img_size, latent_dim, dataloader, ckpt_dir, \\\n","                 epochs, save_n_epoch, lr = 1e-4, load_path=None):\n","        os.makedirs(ckpt_dir, exist_ok=True)\n","        os.makedirs('./results/', exist_ok=True)\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        \n","        self.img_size = img_size\n","        self.latent_dim = latent_dim\n","        self.num_layers = int(log2(img_size)-1)\n","        \n","        self.g = Generator(img_size, latent_dim).to(self.device)\n","        self.d = Discriminator(img_size).to(self.device)\n","        \n","        self.dataloader = dataloader\n","        self.ckpt_dir = ckpt_dir\n","        \n","        self.best_epoch = 1\n","        self.start_epoch = 1\n","        self.epochs = epochs\n","        self.save_n_epoch = save_n_epoch\n","        \n","        self.G_opt = torch.optim.Adam(self.g.parameters(), lr=lr, betas=(0.5, 0.9))\n","        self.D_opt = torch.optim.Adam(self.d.parameters(), lr=lr, betas=(0.5, 0.9))\n","        \n","        \n","        if load_path is not None:\n","            self.load_state_dict(load_path)\n","            print(\"sucessful load state dict !!!!!!\")\n","            print(f\"start from epoch {self.start_epoch}\")\n","    \n","    def state_dict(self, epoch):\n","        return {\n","            \"epoch\": epoch,\n","            \"g_model\": self.g.state_dict(),\n","            \"d_model\": self.d.state_dict()\n","        }\n","    \n","    def load_state_dict(self, path):\n","        state_dict = torch.load(path)\n","        self.g.load_state_dict(state_dict['g_model'])\n","        self.d.load_state_dict(state_dict['d_model'])\n","        self.start_epoch = state_dict['epoch']\n","        \n","    def d_train_step(self, real_img):\n","        batch_size = real_img.size(0)\n","        requires_grad(self.g, False)\n","        requires_grad(self.d, True)\n"," \n","        styles = get_g_input(batch_size, self.img_size, \n","                            self.num_layers, self.latent_dim, \n","                            self.device)                         \n","\n","        fake_img = self.g(styles)\n","        fake_pred = self.d(fake_img)\n","        real_pred = self.d(real_img.requires_grad_())\n","        \n","        # gradient penalty\n","        alpha = torch.rand([batch_size, 1, 1, 1]).to(self.device)\n","        mix_img = alpha * fake_img + (1 - alpha) * real_img\n","        mix_pred = self.d(mix_img)\n","        gp = gradient_penalty(mix_img, mix_pred)\n","        d_loss = d_loss_fn(real_pred, fake_pred) + gp\n","        \n","        self.d.zero_grad()\n","        d_loss.backward()\n","        self.D_opt.step()\n","        return d_loss\n","    \n","    def g_train_step(self, real_img):\n","        batch_size = real_img.size(0)\n","        requires_grad(self.g, True)\n","        requires_grad(self.d, False)\n","        \n","        styles = get_g_input(batch_size, self.img_size, \n","                            self.num_layers, self.latent_dim, \n","                            self.device)  \n","        fake_img = self.g(styles)\n","        fake_pred = self.d(fake_img)\n","        g_loss = g_loss_fn(fake_pred)\n","\n","        self.g.zero_grad()\n","        g_loss.backward()\n","        self.G_opt.step()\n","        return g_loss\n","        \n","    def train(self):\n","        for epoch in tqdm(range(self.start_epoch, self.epochs+1), desc=f\"Training progress\"):\n","            start = time.time()\n","            print(f'Start of epoch {epoch}')\n","    \n","            for i, img in enumerate(self.dataloader):\n","                img = img.to(self.device)\n","                self.G_opt.zero_grad()\n","                self.D_opt.zero_grad()\n","                \n","                d_loss = self.d_train_step(img)\n","                if i % 5 == 0:\n","                    g_loss = self.g_train_step(img)\n","                \n","                if i > 1500:\n","                    break\n","                   \n","            \n","            if self.best_epoch  > g_loss:\n","                torch.save(self.state_dict(epoch), f\"{self.ckpt_dir}/best_epoch.pt\")\n","                print(f\"!!!!!!!!!!!!! saving best epoch {epoch} state dict !!!!!!!```````\")\n","                self.best_epoch = g_loss\n","                \n","            if epoch % self.save_n_epoch == 0:\n","                self.generate_and_create_image(epoch)\n","                torch.save(self.state_dict(epoch), f\"{self.ckpt_dir}/weight_epoch{epoch}.pt\")\n","                print(f\"sucessful saving epoch {epoch} state dict !!!!!!!\")\n","                \n","            time_minutes = (time.time() - start) / 60\n","            print(f\"epoch: {epoch}, D loss: {d_loss.data :.4f} ~~~~~~\")\n","            print(f\"epoch: {epoch}, G loss: {g_loss.data :.4f} ~~~~~~\")\n","            print (f'Time taken for epoch {epoch} is {time_minutes:.3f} min\\n') \n","        print(\"finish training: ~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n","    \n","    def generate_and_create_image(self, epoch):\n","        self.g.eval()\n","        styles = get_g_input(16, self.img_size, \n","                            self.num_layers, self.latent_dim, \n","                            self.device)  \n","        fake_img = self.g(styles)\n","        num_rows = 4\n","        num_columns = 4\n","        fig, axs = plt.subplots(num_rows, num_columns, figsize=(8, 8))\n","\n","        for i in range(num_rows):\n","            for j in range(num_columns):\n","                ax = axs[i, j]\n","                index = i * num_columns + j\n","                img = (fake_img[index] + 1) / 2\n","                img = img.clamp(0, 1)\n","\n","                # Display the image\n","                ax.imshow(img.permute(1, 2, 0).cpu().detach().numpy())\n","                ax.axis('off')\n","        \n","        self.g.train()\n","        plt.savefig(f'./results/result_img{epoch}.jpg')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["clpt_dir = './model_weight/'\n","#load_path = None\n","trainer = Trainer(64, 256, train_data, clpt_dir, 100, 5)\n","trainer.train()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":803742,"sourceId":1377922,"sourceType":"datasetVersion"},{"datasetId":1307206,"sourceId":2177371,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
